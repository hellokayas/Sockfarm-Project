{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(alg='fraudar', data='alpha')\n"
     ]
    }
   ],
   "source": [
    "%run random_attack.py --data alpha --alg fraudar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UGFraud.Utils.helper import *\n",
    "from UGFraud.Detector.Fraudar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def listToSparseMatrix(edgesSource, edgesDest):\n",
    "    m = max(edgesSource) + 1\n",
    "    n = max(edgesDest) + 1\n",
    "    M = sparse.coo_matrix(([1] * len(edgesSource), (edgesSource, edgesDest)), shape=(m, n))\n",
    "    M1 = M > 0\n",
    "    return M1.astype('int')\n",
    "def runFraudar(graph, multiple=0):\n",
    "    new_upriors = node_attr_filter(graph, 'types', 'user', 'prior')\n",
    "    new_rpriors = edge_attr_filter(graph, 'types', 'review', 'prior')\n",
    "    # print('Start detection on the new graph with Fraudar')\n",
    "    user_to_product = {}\n",
    "    prod_to_user = {}\n",
    "    u_id_dict = node_attr_filter(graph, 'types', 'user', 'types')\n",
    "    for u_id in u_id_dict.keys():\n",
    "        if u_id not in user_to_product:\n",
    "            user_to_product[u_id] = []\n",
    "        for p_id in graph[u_id].keys():\n",
    "            if p_id not in prod_to_user:\n",
    "                prod_to_user[p_id] = []\n",
    "                user_to_product[u_id].append(p_id)\n",
    "                prod_to_user[p_id].append(u_id)\n",
    "    u_id2idx = {}\n",
    "    p_id2idx = {}\n",
    "    idx2u_id = {}\n",
    "    idx2p_id = {}\n",
    "    i = 0\n",
    "    for u_id in user_to_product.keys():\n",
    "        u_id2idx[u_id] = i\n",
    "        idx2u_id[i] = u_id\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    for p_id in prod_to_user.keys():\n",
    "        p_id2idx[p_id] = i\n",
    "        idx2p_id[i] = p_id\n",
    "        i += 1\n",
    "\n",
    "    edgesSource = []\n",
    "    edgesDest = []\n",
    "    for u_id in u_id_dict.keys():\n",
    "        for p_id in graph[u_id].keys():\n",
    "            edgesSource.append(u_id2idx[u_id])\n",
    "            edgesDest.append(p_id2idx[p_id])\n",
    "    M = listToSparseMatrix(edgesSource, edgesDest)\n",
    "    # print(\"finished reading data \")\n",
    "\n",
    "    if multiple == 0:\n",
    "        # detect all dense blocks \n",
    "        res = detect_blocks(M, logWeightedAveDegree)\n",
    "    else:\n",
    "        # detect the top #multiple dense blocks\n",
    "        res = detectMultiple(M, logWeightedAveDegree, multiple)\n",
    "\n",
    "    detected_users = {}\n",
    "    weight_dict = {}\n",
    "    for lwRes in res:\n",
    "        detected_u_idx = lwRes[0][0]\n",
    "        detected_p_idx = lwRes[0][1]\n",
    "        weight = lwRes[1]\n",
    "        weight_dict[weight] = weight\n",
    "        for i in detected_u_idx:\n",
    "            uid_tmp = idx2u_id[i]\n",
    "            if uid_tmp not in detected_users.keys():\n",
    "                detected_users[uid_tmp] = weight\n",
    "\n",
    "    max_den = res[0][1]\n",
    "    min_den = res[-1][1]\n",
    "    den_interval = max_den - min_den\n",
    "\n",
    "    ranked_rpriors = [(review, new_rpriors[review]) for review in new_rpriors.keys()]\n",
    "    ranked_rpriors = sorted(ranked_rpriors, reverse=True, key=lambda x: x[1])\n",
    "    r_max, r_mean, r_min = ranked_rpriors[0][1], ranked_rpriors[int(len(ranked_rpriors) / 2)][1], ranked_rpriors[-1][1]\n",
    "    aux_rpriors = cp.deepcopy(new_rpriors)\n",
    "    for i, p in aux_rpriors.items():\n",
    "        if r_max - r_min == 0:\n",
    "            new_rpriors[i] = 0\n",
    "        else:\n",
    "            new_rpriors[i] = (p - r_min) / (r_max - r_min)\n",
    "\n",
    "    user_density = {}\n",
    "    for u in new_upriors.keys():\n",
    "        if u in detected_users.keys():\n",
    "            user_density[u] = (detected_users[u] - min_den) / den_interval\n",
    "        else:\n",
    "            user_density[u] = 1e-6\n",
    "\n",
    "    user_prob = {}\n",
    "    review_prob = {}\n",
    "    for review in new_rpriors.keys():\n",
    "        review_prob.update({review: 1e-6})\n",
    "        user_prob.update({review[0]: 1e-6})\n",
    "    print(len(detected_users))\n",
    "#     print(detected_users['302'])\n",
    "\n",
    "    for user in detected_users.keys():\n",
    "        user_prob.update({user: user_density[user]})\n",
    "        for prod in graph[user].keys():\n",
    "            review_prob.update({(user, prod): user_density[user]})\n",
    "\n",
    "    return user_prob, review_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UGFraud.Detector.fBox import *\n",
    "def runfBox(graph, t, k):\n",
    "    user_priors = node_attr_filter(graph, 'types', 'user', 'prior')\n",
    "    review_priors = edge_attr_filter(graph, 'types', 'review', 'prior')\n",
    "\n",
    "    # run fBox\n",
    "    model = fBox(graph)\n",
    "    num_detected_users = []\n",
    "\n",
    "    detected_users_by_degree, detected_products_by_degree = model.run(t, k)\n",
    "    detected_users = set()\n",
    "    for d, user_list in detected_users_by_degree.items():\n",
    "        detected_users.update([u for u in user_list])\n",
    "\n",
    "    num_detected_users.append(len(detected_users))\n",
    "\n",
    "    detected_products = set()\n",
    "    for d, prod_list in detected_products_by_degree.items():\n",
    "        detected_products.update([p for p in prod_list])\n",
    "\n",
    "    result_uid = []\n",
    "    user_prob = {}  # result_prob means user_prob\n",
    "    review_prob = {}\n",
    "    for u, v in user_priors.items():\n",
    "        result_uid.append(u)\n",
    "        if u in detected_users:\n",
    "            user_prob.update({u: user_priors.get(u)})\n",
    "        else:\n",
    "            user_prob.update({u: 1e-7})\n",
    "\n",
    "    for user_prod in graph.edges:\n",
    "        if user_prod[0] in detected_users:\n",
    "            review_prob[(user_prod[0], user_prod[1])] = review_priors.get((user_prod[0], user_prod[1]))\n",
    "        else:\n",
    "            review_prob[(user_prod[0], user_prod[1])] = 0\n",
    "\n",
    "    return user_prob, review_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_ground_truth = edge_attr_filter(G, 'types', 'review', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ../../UGFraud/UGFraud/Demo/Yelp_graph_data.json into the nextorkx graph\n"
     ]
    }
   ],
   "source": [
    "G_test = load_graph(\"../../UGFraud/UGFraud/Demo/Yelp_graph_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prod', 'user'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [G_test.nodes[n][\"types\"] for n in G_test.nodes]\n",
    "set(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rating': 1,\n",
       " 'label': 1,\n",
       " 'date': 'None',\n",
       " 'prior': 0.35048557119705304,\n",
       " 'types': 'review'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_test.edges[(\"201\", \"0\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prior': 0.3951113464084369, 'types': 'prod'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_test.nodes[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes[\"u7188\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = G.copy()\n",
    "nodes_update = {\n",
    "    n: {\n",
    "        \"types\": \"user\" if n[0] == \"u\" else \"prod\",\n",
    "        \"prior\": 0,\n",
    "       }\n",
    "    for n in G2.nodes\n",
    "}\n",
    "\n",
    "edges_update = {\n",
    "    e: {\n",
    "        \"prior\": 0,\n",
    "        \"types\": \"review\",\n",
    "    }\n",
    "    for e in G2.edges\n",
    "}\n",
    "\n",
    "nx.set_node_attributes(G2, nodes_update)\n",
    "nx.set_edge_attributes(G2, edges_update)\n",
    "\n",
    "for n, label in zip(\"u\" + data_gt_df[\"id\"].astype(str), data_gt_df[\"label\"]):\n",
    "    if n in G2.nodes:\n",
    "        G2.nodes[n][\"label\"] = (label + 1) / 2\n",
    "        for e in G2.out_edges(\"u3\"):\n",
    "            G2.edges[e][\"label\"] = (label + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969\n"
     ]
    }
   ],
   "source": [
    "import copy as cp\n",
    "userBelief, reviewBelief = runFraudar(G2, multiple=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userBelief[\"u3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run in 0.093 secs\n",
      "1e-07\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "userBelief, reviewBelief = runfBox(G2, t=0.5, k=70)\n",
    "print(max([userBelief[u] for u in userBelief]))\n",
    "print(min([reviewBelief[u] for u in reviewBelief]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userBelief[\"u3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "import uuid\n",
    "np.random.randint(0, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
